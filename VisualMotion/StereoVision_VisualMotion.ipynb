{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DepthEstimation](https://github.com/adomakor412/ComputerVision/blob/master/VisualMotion/Questions_IMG/Question1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Solution](http://elvers.us/perception/aperture/)\n",
    "\n",
    "## Take the partial derivative of D\n",
    "\n",
    "$\\nabla D = (\\delta f) B/d + (\\delta B) f/d + -(\\delta d)fB (1/d)^2$\n",
    "\n",
    "$\\nabla D = (\\delta f) B/d + (\\delta B) f/d + -(\\delta d)\\frac{Z^2}{fd}$\n",
    "\n",
    "**Baseline** when $(\\delta f) = (\\delta d) = 0$\n",
    "\n",
    "• $\\delta D = (\\delta B) \\frac{f}{d}$\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto \\delta B $\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto  \\frac{1}{d} $\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto f $\n",
    "\n",
    "**focal length** when $(\\delta B) = (\\delta d) = 0$\n",
    "\n",
    "• $\\delta D = (\\delta f) \\frac{B}{d}$\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto \\delta f $\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto  \\frac{1}{d} $\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto B $\n",
    "\n",
    "**disparity** when $(\\delta f) = (\\delta B) = 0$\n",
    "\n",
    "• $\\delta D = -(\\delta d)\\frac{Z^2}{fd}$\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto \\delta d $\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto  Z^2 $\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto \\frac{1}{f} $\n",
    "\n",
    "• $\\delta D \\displaystyle\\propto \\frac{1}{d} $\n",
    "\n",
    "**disparity** when $(\\delta D) =  0$\n",
    "\n",
    "• There is no error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Question2](https://github.com/adomakor412/ComputerVision/blob/master/VisualMotion/Questions_IMG/Question2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Solution](https://www.pyimagesearch.com/2015/01/19/find-distance-camera-objectmarker-using-python-opencv/)\n",
    "\n",
    "No, pure rotation only leads to 2D information. You can produce (panoramic) \"mosaicing\" effect by rotation. For pure Translation (T<sub>x</sub>,T<sub>y</sub>,T<sub>z</sub>) consider the case where the camera is moving only in a plane (T<sub>z</sub> = 0) and the focal length remains the same–a Parallel Motion field (not a Radial Motion field). You are able to solve for the depth by estimating the relative change in the **Z** direction of corresponding points: you CANNOT obtain 3D information by the special case of Parallel Motion field in pure Translation, because you cancel out 2D information. Multiple images are taken as the camera moves.\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "           v_{x} \\\\\n",
    "           v_{y}\n",
    "         \\end{bmatrix}\n",
    "         = \\frac{\\textbf{1}}{\\textbf{Z}} \n",
    "         \\begin{bmatrix}\n",
    "           -f & 0 & x \\\\\n",
    "           0 & -f & y\n",
    "         \\end{bmatrix}\n",
    "         \\begin{bmatrix}\n",
    "           T_{x} \\\\\n",
    "           T_{y} \\\\\n",
    "           T_{z}\n",
    "         \\end{bmatrix}\n",
    "         +\n",
    "         \\frac{\\textbf{1}}{\\textbf{f}} \n",
    "         \\begin{bmatrix}\n",
    "           xy & −(x^2 + f^2) & fy\\\\\n",
    "           (x^2 + f^2) & -xy & -fx\n",
    "         \\end{bmatrix}\n",
    "         \\begin{bmatrix}\n",
    "           w_{x} \\\\\n",
    "           w_{y} \\\\\n",
    "           w_{z}\n",
    "         \\end{bmatrix}\n",
    "         $$\n",
    "         \n",
    "For correspondence, the assumption is taken at different times, t, in matching the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Question3](https://github.com/adomakor412/ComputerVision/blob/master/VisualMotion/Questions_IMG/Question3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Solution](http://elvers.us/perception/aperture/)\n",
    "\n",
    "The aperture problem occurs in the optical flow equation when you are estimating the relative motion between the camera and the scene of image point. For a small window view, a point generates two unknowns in its 2D movement. The aperture problem occurs when you can only detect only 1D movement of a point relative to the motion of the camera accurately. For each point you have two unknowns. You need at least two points that are on the same surface to accurately estimate 2D motion relative to the camera. Assume densely packed points, so that the multiple points belong to the same surface. \n",
    "\n",
    "If a corner is visible through the aperture, you have a constraint. Use the vector relationship on either side of the vertex of that corner and solve for the direction of motion perpendicular to an edge of the aperture. The angle in between the corner can be used to correct your 2D estimation between 2 images taken at different times of a moved point. (This is easier if you find a corner that is 90º i.e. edges orthogonal to one another!)\n",
    "\n",
    "In general:\n",
    "\n",
    "• only the component of the motion field in the direction of the spatial image gradient can be determined.\n",
    "\n",
    "• the component perpendicular to the spatial gradient is not constrained by the optical flow equation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Question4](https://github.com/adomakor412/ComputerVision/blob/master/VisualMotion/Questions_IMG/Question4.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Solution](http://ccvcl.org/professor-zhigang-zhu/computer-vision-fall-2020/csc-i6716-fall-2020-assignment-4/)\n",
    "\n",
    "## Fundamental Matrix\n",
    "\n",
    "#### Left Image\n",
    "![Left Image]()\n",
    "\n",
    "#### Right Image\n",
    "![Right Image]()\n",
    "\n",
    "#### Fundamental Matrix\n",
    "-1.7318491e-06  -3.4187600e-05   1.6786188e-02\n",
    "   3.1294581e-05  -2.8125475e-06   2.5136339e-03\n",
    "  -1.6814367e-02  -3.2577843e-03   9.9970924e-01\n",
    "\n",
    "#### Epipoles ####\n",
    "\n",
    "#### Accuracy ####\n",
    "\n",
    "#### Bonus automated point selection: using *constant Intensity* assumption of a 3x3\n",
    "\n",
    "## Feature Based Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
